\documentclass{ximera}
\input{../preamble.tex}

\title{Linear Transformations of Abstract Vector Spaces} \license{CC BY-NC-SA 4.0}

\begin{document}
\begin{abstract}
\end{abstract}
\maketitle

\section*{Linear Transformations of Abstract Vector Spaces}

Recall that a transformation $T:\mathbb{R}^n\rightarrow \mathbb{R}^m$ is called a \dfn{linear transformation} if the following are true for all vectors ${\bf u}$ and ${\bf v}$ in $\mathbb{R}^n$, and scalars $k$.
\begin{equation*}
T(k{\bf u})= kT({\bf u})
\end{equation*}
\begin{equation*}
T({\bf u}+{\bf v})= T({\bf u})+T({\bf v})
\end{equation*}

We generalize this definition as follows.

\begin{definition}\label{def:lintransgeneral}
Let $V$ and $W$ be vector spaces. A transformation $T:V\rightarrow W$ is called a \dfn{linear transformation} if the following are true for all vectors ${\bf u}$ and ${\bf v}$ in $V$, and scalars $k$.
\begin{equation*}
T(k{\bf u})= kT({\bf u})
\end{equation*}
\begin{equation*}
T({\bf u}+{\bf v})= T({\bf u})+T({\bf v})
\end{equation*}
\end{definition}

\begin{example}\label{ex:abstvectsplintransM22}
Recall that $\mathbb{M}_{n,n}$ is the set of all $n\times n$ matrices.  In Example \ref{ex:setofmatricesvectorspace} of \href{https://ximera.osu.edu/oerlinalg/LinearAlgebra/VSP-0050/main}{Abstract Vector Spaces} we demonstrated that $\mathbb{M}_{n,n}$ together with operations of matrix addition and scalar multiplication is a vector space.

Let $T_Q:\mathbb{M}_{n,n}\rightarrow \mathbb{M}_{n,n}$ be a transformation defined by $T_Q(A)=QA$, where $Q$ is fixed $n\times n$ matrix.  Show that $T_Q$ is a linear transformation.
\begin{explanation}
We verify the linearity properties using properties of matrix-matrix and matrix-scalar multiplication.  (See Theorem \ref{th:propertiesofmatrixmultiplication} of \href{https://ximera.osu.edu/oerlinalg/LinearAlgebra/MAT-0020/main}{Matrix Multiplication}.)  For $A$ and $B$ in $\mathbb{M}_{n,n}$ and a scalar $k$ we have:
$$T_Q(kA)=Q(kA)=k(QA)=kT_Q(A)$$
$$T_Q(A+B)=Q(A+B)=QA+QB=T_Q(A)+T_Q(B)$$
\end{explanation}
\end{example}

\begin{example}\label{ex:abstvecsplintrans2}
Recall that $\mathbb{P}^3$ is the set of polynomials of degree $3$ or less than $3$.  In Example \ref{ex:pnisavectorspace} of \href{https://ximera.osu.edu/oerlinalg/LinearAlgebra/VSP-0050/main}{Abstract Vector Spaces} we showed that $\mathbb{P}^3$ together with operations of polynomial addition and scalar multiplication is a vector space. 

Suppose $T:\RR^3\rightarrow\mathbb{P}^3$ is a linear transformation such that 
$$T(\vec{i})=1+x-2x^2+x^3$$
$$T(\vec{j})=x+2x^3$$
$$T(\vec{k})=3+x^3$$
Find the image of $\begin{bmatrix}1\\-2\\1\end{bmatrix}$ under $T$.
\begin{explanation}
\begin{align*}
    T\left(\begin{bmatrix}1\\-2\\1\end{bmatrix}\right)&=T(\vec{i}-2\vec{j}+\vec{k})=T(\vec{i})-2T(\vec{j})+T(\vec{k})\\
    &=(1+x-2x^2+x^3)-2(x+2x^3)+(3+x^3)\\
    &=4-x-2x^2-2x^3
\end{align*}
\end{explanation}
\end{example}

\begin{example}\label{ex:nonlinabstvectsp}
Let $T:\mathbb{M}_{3,3}\rightarrow \RR$ be a transformation such that $T(A)=\mbox{rank}(A)$.  Show that $T$ is not linear.
\begin{explanation}
To show that $T$ is not linear it suffices to find two matrices $A$ and $B$ such that $T(A+B)\neq T(A)+T(B)$.  Observe that if we pick $A$ and $B$ so that each has rank $3$ we would have $T(A)+T(B)=\mbox{rank}(A)+\mbox{rank}(B)=6$ while $T(A+B)=\mbox{rank}(A+B)\leq 3$.  Clearly  $T(A+B)\neq T(A)+T(B)$.  This argument is sufficient, but if we want to have a specific example, we can find one.
Let $$A=\begin{bmatrix}1&0&0\\0&1&0\\0&0&1\end{bmatrix} \quad\text{and}\quad B=\begin{bmatrix}-1&0&0\\0&1&0\\0&0&-1\end{bmatrix}$$
Then
$$T(A)=3\quad\text{and}\quad T(B)=3$$
$$T(A+B)=T\left(\begin{bmatrix}0&0&0\\0&2&0\\0&0&0\end{bmatrix}\right)=1$$
Thus, $1=T(A+B)\neq T(A)+T(B)=6$.
\end{explanation}
\end{example}

\subsection*{Linear Transformations and Bases}

\begin{exploration}\label{init:tij}  Suppose we want to define a linear transformation $T:\RR^2\rightarrow \RR^2$ by $$T(\vec{i})=\begin{bmatrix}3\\-2\end{bmatrix}\quad\text{and}\quad T(\vec{j})=\begin{bmatrix}-1\\2\end{bmatrix}$$  
Is this information sufficient to define $T$?  
To answer this question we will try to determine what $T$ does to an arbitrary vector of $\RR^2$.  

If $\vec{v}$ is a vector in $\RR^2$, then $\vec{v}$ can be uniquely expressed as a linear combination of $\vec{i}$ and $\vec{j}$
$$\vec{v}=a\vec{i}+b\vec{j}$$  By linearity of $T$ we have $$T(\vec{v})=T(a\vec{i}+b\vec{j})=aT(\vec{i})+bT(\vec{j})=a\begin{bmatrix}3\\-2\end{bmatrix}+b\begin{bmatrix}-1\\2\end{bmatrix}$$
This shows that the image of every vector of $\RR^2$ under $T$ is completely determined by the action of $T$ on the standard unit vectors $\vec{i}$ and $\vec{j}$.  

Vectors $\vec{i}$ and $\vec{j}$ form a standard basis of $\RR^2$.  What if we want to use a different basis?  

Let $\mathcal{B}=\left\{\begin{bmatrix}1\\1\end{bmatrix},\begin{bmatrix}2\\-1\end{bmatrix}\right\}$ be our basis of choice for $\RR^2$. (How would you verify that $\mathcal{B}$ is a basis of $\RR^2$?) And suppose we want to define a linear transformation $S:\RR^2\rightarrow \RR^2$ by $$S\left(\begin{bmatrix}1\\1\end{bmatrix}\right)=\begin{bmatrix}0\\-1\end{bmatrix}\quad\text{and}\quad S\left(\begin{bmatrix}2\\-1\end{bmatrix}\right)=\begin{bmatrix}2\\0\end{bmatrix}$$
Is this enough information to define $S$?

Because $\begin{bmatrix}1\\1\end{bmatrix},\begin{bmatrix}2\\-1\end{bmatrix}$ form a basis of $\RR^2$, every element $\vec{v}$ of $\RR^2$ can be written as a unique linear combination $$\vec{v}=a\begin{bmatrix}1\\1\end{bmatrix}+b\begin{bmatrix}2\\-1\end{bmatrix}$$
We can find $S(\vec{v})$ as follows:
$$S(\vec{v})=S\left(a\begin{bmatrix}1\\1\end{bmatrix}+b\begin{bmatrix}2\\-1\end{bmatrix}\right)=a\begin{bmatrix}0\\-1\end{bmatrix}+b\begin{bmatrix}2\\0\end{bmatrix}$$

Again, we see how a linear transformation is completely determined by its action on a basis.

Theorem \ref{th:uniquerep} assures us that given a basis, every vector has a unique representation as a linear combination of the basis vectors.  Imagine what would happen if this were not the case.  In the first part of this exploration, for instance, we might have been able to represent $\vec{v}$ as $a\vec{i}+b\vec{j}$ and $c\vec{i}+d\vec{j}$ ($a\neq c$ or $b\neq d$).  This would have resulted in $\vec{v}$ mapping to two different elements: $aT(\vec{i})+bT(\vec{j})$ and $cT(\vec{i})+dT(\vec{j})$, implying that $T$ is not even a function.  

\end{exploration}

Let $\mathcal{B}=\{\vec{v}_1,\ldots,\vec{v}_p\}$ be a basis of a vector space $V$.  To define a linear transformation $T:V\rightarrow W$, it is sufficient to state the image of each basis vector under $T$.  Once the images of the basis vectors are established, we can determine the images of all vectors of $V$ as follows:

Given any vector $\vec{v}$ of $V$, write $\vec{v}$ as a linear combination of the elements of $\mathcal{B}$
$$\vec{v}=a_1\vec{v}_1+\ldots+a_p\vec{v}_p.$$ 
Then
$$T(\vec{v})=T(a_1\vec{v}_1+\ldots+a_p\vec{v}_p)=a_1T(\vec{v}_1)+\ldots+a_pT(\vec{v}_p).$$







\subsection*{Coordinate Vectors}
Transformations that map vectors to their coordinate vectors will prove to be of great importance.  In this section we will prove that such transformations are linear and give several examples.

If $V$ is a vector space, and  $\mathcal{B}=\{\vec{v}_1, \ldots ,\vec{v}_n\}$ is an ordered basis for $V$ then any vector $\vec{v}$ of $V$ can be uniquely expressed as $\vec{v}=a_1\vec{v}_1+\ldots +a_n\vec{v}_n$ for some scalars $a_1, \ldots ,a_n$.  Vector $[\vec{v}]_{\mathcal{B}}$ in $\RR^n$ given by 
$$[\vec{v}]_{\mathcal{B}}=\begin{bmatrix}a_1\\a_2\\\vdots\\a_n\end{bmatrix}$$
is said to be the \dfn{coordinate vector for $\vec{v}$ with respect to the ordered basis $\mathcal{B}$}.  (See Definition \ref{def:coordvector}.)  

It turns out that the transformation $T:V\rightarrow \RR^n$ defined by $T(\vec{v})=[\vec{v}]_{\mathcal{B}}$ is linear.  Before we prove linearity of $T$, consider the following examples.

\begin{example}\label{ex:abstvectsplintranscoordvect1}
Consider $\mathbb{M}_{2,2}$.  Let $\mathcal{B}=\left\{\begin{bmatrix}1&0\\0&0\end{bmatrix}, \begin{bmatrix}0&1\\0&0\end{bmatrix}, \begin{bmatrix}0&0\\1&0\end{bmatrix}, \begin{bmatrix}0&0\\0&1\end{bmatrix}\right\}$ be an ordered basis for $\mathbb{M}_{2,2}$.  (You should do a quick mental check that $\mathcal{B}$ is a legitimate basis.)  Define $T:\mathbb{M}_{2,2}\rightarrow \RR^4$ by $T(A)=[A]_{\mathcal{B}}$.  Find $T\left(\begin{bmatrix}-2&3\\1&-5\end{bmatrix}\right)$.
\begin{explanation}
We need to find the coordinate vector for $\begin{bmatrix}-2&3\\1&-5\end{bmatrix}$ with respect to $\mathcal{B}$.
$$\begin{bmatrix}-2&3\\1&-5\end{bmatrix}=-2\begin{bmatrix}1&0\\0&0\end{bmatrix}+ 3\begin{bmatrix}0&1\\0&0\end{bmatrix}+ \begin{bmatrix}0&0\\1&0\end{bmatrix}+ (-5)\begin{bmatrix}0&0\\0&1\end{bmatrix}$$
This gives us:
$$T\left(\begin{bmatrix}-2&3\\1&-5\end{bmatrix}\right)=\left[\begin{bmatrix}-2&3\\1&-5\end{bmatrix}\right]_{\mathcal{B}}=\begin{bmatrix}-2\\3\\1\\-5\end{bmatrix}$$
\end{explanation}
\end{example}

\begin{example}\label{ex:abstvectsplintranspoly}
Recall that $\mathbb{P}^2$ is the set of polynomials of degree $2$ or less than $2$.  In Example \ref{ex:deg_le_2vectorspace} of \href{https://ximera.osu.edu/oerlinalg/LinearAlgebra/VSP-0050/main}{Abstract Vector Spaces} we showed that $\mathbb{P}^2$ is a vector space. 
\begin{enumerate}
    \item \label{item:lintranspolycoordvect1} Let $\mathcal{B}_1=\{1, x, x^{2}\}$ be an ordered basis for $\mathbb{P}^2$.  (It is easy to verify that $\mathcal{B}_1$ is a basis.) If $T:\mathbb{P}^2\rightarrow \RR^3$ is given by $T(p)=[p]_{\mathcal{B}_1}$, find $T(2x^2-3x)$.
    \item \label{item:lintranspolycoordvect2}
Let $\mathcal{B}_2=\{1 + x, 1 - x, x + x^{2}\}$ be an ordered basis for $\mathbb{P}^2$. (In Practice Problem \ref{prob:linindabstractvsp1}, you demonstrated that $\mathcal{B}_2$ is a basis.)  If $T:\mathbb{P}^2\rightarrow \RR^3$ is given by $T(p)=[p]_{\mathcal{B}_2}$, find $T(2x^2-3x)$.
\end{enumerate}
\begin{explanation}
\ref{item:lintranspolycoordvect1}  We express $2x^2-3x$ as a linear combination of elements of $\mathcal{B}_1$.
$$2x^2-3x=0\cdot 1+ (-3)x+2x^2$$
Therefore $$[2x^2-3x]_{\mathcal{B}_1}=\begin{bmatrix}0\\-3\\2\end{bmatrix}$$
Note that it is important to keep the basis elements in the same order in which they are listed, as the order of components of the coordinate vector depends on the order of the basis elements.  We conclude that
$$T(2x^2-3x)=\begin{bmatrix}0\\-3\\2\end{bmatrix}$$

\ref{item:lintranspolycoordvect2} Our goal is to express $2x^2-3x$ as a linear combination of the elements of $\mathcal{B}_2$.  Thus, we need to find coefficients $a$, $b$ and $c$ such that
$$2x^2-3x=a(1+x)+b(1-x)+c(x+x^2)=(a+b)+(a-b+c)x+cx^2$$
This gives us a system of linear equations:
$$\begin{array}{ccccccc}
      a & +&b&&&= &0 \\
	 a& -&b&+&c&=&-3\\
     & &&&c&=&2
    \end{array}$$
    Solving the system yields $a=-\frac{5}{2}$, $b=\frac{5}{2}$ and $c=2$.  Thus
    $$T(2x^2-3x)=[2x^2-3x]_{\mathcal{B}_2}=\begin{bmatrix}-5/2\\5/2\\2\end{bmatrix}$$
\end{explanation}
\end{example}

\begin{theorem}\label{th:coordvectmappinglinear}
Let $V$ be an $n$-dimensional vector space, and let $\mathcal{B}$ be an ordered basis for $V$.  Then  $T:V\rightarrow \RR^n$ given by $T(\vec{v})=[\vec{v}]_{\mathcal{B}}$ is a linear transformation.
\end{theorem}
\begin{proof}
First observe that Theorem \ref{th:uniquerep} of \href{https://ximera.osu.edu/oerlinalg/LinearAlgebra/VSP-0060/main}{Bases and Dimension of Abstract Vector Spaces} guarantees that there is only one way to represent each element of $V$ as a linear combination of elements of $\mathcal{B}$.  Thus each element of $V$ maps to exactly one element of $\RR^n$, as long as the order in which elements of $\mathcal{B}$ appear is taken into account.  This proves that $T$ is a function, or a transformation.  We will now prove that $T$ is linear.

Let $\vec{v}$ be an element of $V$.  We will first show that $T(k\vec{v})=kT(\vec{v})$.  Suppose $\mathcal{B}=\{\vec{v}_1, \ldots ,\vec{v}_n\}$, then $\vec{v}$ can be written as a unique linear combination:
$$\vec{v}=a_1\vec{v}_1+ \ldots +a_n\vec{v}_n$$
We have:
\begin{align*}
    T(k\vec{v})&=T(k(a_1\vec{v}_1+ \ldots +a_n\vec{v}_n))\\
    &=T((ka_1)\vec{v}_1+ \ldots +(ka_n)\vec{v}_n)\\
    &=\begin{bmatrix}ka_1\\\vdots\\ka_n\end{bmatrix}=k\begin{bmatrix}a_1\\\vdots\\a_n\end{bmatrix}=kT(\vec{v})
\end{align*}
We leave it to the reader to verify that $T(\vec{v}+\vec{w})=T(\vec{v})+T(\vec{w})$.  (See Practice Problem \ref{prob:completeproofoflin}.)
\end{proof}

In our final example, we will consider $T$ in the context of a basis of the codomain, as well as a basis of the domain.  This will later help us tackle the question of the matrix of $T$ associated with bases other than the standard basis of $\RR^n$.

\begin{example}\label{ex:subtosub1}
Let
$$\vec{v}_1=\begin{bmatrix}1\\2\\0\end{bmatrix}\quad\text{and}\quad\vec{v}_2=\begin{bmatrix}0\\1\\1\end{bmatrix}$$
$$\vec{w}_1=\begin{bmatrix}1\\0\\1\end{bmatrix}\quad\text{and}\quad\vec{w}_2=\begin{bmatrix}1\\0\\0\end{bmatrix}$$
Let $$V=\text{span}(\vec{v}_1, \vec{v}_2)\quad\text{and}\quad W=\text{span}(\vec{w}_1, \vec{w}_2)$$

Because each of $\{\vec{v}_1, \vec{v}_2\}$ and $\{\vec{w}_1, \vec{w}_2\}$ is linearly independent, let 
$$\mathcal{B}=\{\vec{v}_1, \vec{v}_2\}\quad\text{and}\quad\mathcal{C}=\{\vec{w}_1, \vec{w}_2\}$$
be ordered bases of $V$ and $W$, respectively.


Define a linear transformation $T:V\rightarrow W$ by 
$$T(\vec{v}_1)=2\vec{w}_1-3\vec{w}_2\quad\text{and} \quad T(\vec{v}_2)=-\vec{w}_1+4\vec{w}_2$$

\begin{enumerate}
\item \label{item:subtosub1a}
Verify that $\vec{v}=\begin{bmatrix}2\\5\\1\end{bmatrix}$ is in $V$ and find the coordinate vector $[\vec{v}]_{\mathcal{B}}$.
\item\label{item:subtosub1b}
Find $T(\vec{v})$ and the coordinate vector $[T(\vec{v})]_{\mathcal{C}}$.
\end{enumerate}
\begin{explanation}
\ref{item:subtosub1a} We need to express $\vec{v}$ as a linear combination of $\vec{v}_1$ and $\vec{v}_2$.  This can be done by observation or by solving the equation
$$\begin{bmatrix}1&0\\2&1\\0&1\end{bmatrix}\begin{bmatrix}a\\b\end{bmatrix}=\begin{bmatrix}2\\5\\1\end{bmatrix}$$
We find that $a=2$ and $b=1$, so $\vec{v}=2\vec{v}_1+\vec{v}_2$.  Thus $\vec{v}$ is in $V$.  The coordinate vector for $\vec{v}$ with respect to the ordered basis $\mathcal{B}$ is 
$$[\vec{v}]_{\mathcal{B}}=\begin{bmatrix}2\\1\end{bmatrix}$$

\ref{item:subtosub1b} By linearity of $T$ we have \begin{align*}T(\vec{v})=T(2\vec{v}_1+\vec{v}_2)&=2T(\vec{v}_1)+T(\vec{v}_2)\\&=2(2\vec{w}_1-3\vec{w}_2)+(-\vec{w}_1+4\vec{w}_2)\\&=3\vec{w}_1-2\vec{w}_2=\begin{bmatrix}1\\0\\3\end{bmatrix}
\end{align*}

The coordinate vector for $T(\vec{v})$ with respect to the ordered basis $\mathcal{C}$ is 
$$[T(\vec{v})]_{\mathcal{C}}=\begin{bmatrix}3\\-2\end{bmatrix}.$$

%The important observation here is that given a linear transformation defined on the basis elements of $V$ in terms of the basis elements of $W$, we are able to find the image of any $\vec{v}$ in $V$ in terms of the basis elements of $W$. We will visit this idea again in Exploration \ref{init:matlintransgeneral}.

\end{explanation}

\end{example}


%\begin{center}
%\begin{tikzpicture}[scale=1]
%  \filldraw[orange](-0.25,3.5)--(0.25,3.5)--(1.5,0)--(-1.5,0)--cycle;
%  \filldraw[orange] (0,0) ellipse (2cm and 1cm);
%  \filldraw[orange] (0,3.5) ellipse (0.25cm and 0.15cm);
%\end{tikzpicture}

%UNDER CONSTRUCTION -- COMING SOON
%\end{center}

\section*{Practice Problems}
\begin{problem}\label{prob:lintransP2toM22}
Suppose $T:\mathbb{P}^2\rightarrow\mathbb{M}_{2,2}$ is a linear transformation such that 
$$T(1)=\begin{bmatrix}1&0\\0&1\end{bmatrix},\quad T(x)=\begin{bmatrix}1&1\\0&1\end{bmatrix},\quad T(x^2)=\begin{bmatrix}1&1\\1&1\end{bmatrix}$$
Find $T(4-x+3x^2)$.

Answer:$$T(4-x+3x^2)=\begin{bmatrix}\answer{6}&\answer{2}\\\answer{3}&\answer{6}\end{bmatrix}$$

\end{problem}

\begin{problem}
Define $T:\mathbb{M}_{3,3}\rightarrow \RR$ by $T(A)=\mbox{tr}(A)$.  (Recall that $\mbox{tr}(A)$ denotes the \dfn{trace} of $A$, which is the sum of the main diagonal entries of $A$.)

\begin{problem}\label{prob:tracelintrans1}
Find $T\left(\begin{bmatrix}1&2&3\\4&5&6\\7&8&9\end{bmatrix}\right)$

Answer: $$T\left(\begin{bmatrix}1&2&3\\4&5&6\\7&8&9\end{bmatrix}\right)=\answer{15}$$
\end{problem}

\begin{problem}\label{prob:tracelintrans2}
Is $T$ a linear transformation?  If so, prove it.  If not, give a counterexample.
\end{problem}
\end{problem}

\begin{problem}
Define $T:\RR^2\rightarrow\mathbb{M}_{2,2}$ by $T\left(\begin{bmatrix}a\\b\end{bmatrix}\right)=\begin{bmatrix}a&1\\1&b\end{bmatrix}$.

\begin{problem}\label{prob:lintransr2toM22part1}
Find $T\left(\begin{bmatrix}2\\-1\end{bmatrix}\right)$.

Answer: $$T\left(\begin{bmatrix}2\\-1\end{bmatrix}\right)=\begin{bmatrix}\answer{2}&\answer{1}\\\answer{1}&\answer{-1}\end{bmatrix}$$
\end{problem}
\begin{problem}\label{prob:lintransr2toM22part2}
Is $T$ a linear transformation?  If so, prove it.  If not, give a counterexample.
\end{problem}
\end{problem}

\begin{problem}  This problem requires the knowledge of how to compute a $3\times 3$ determinant. (For a quick reminder, see Definition \ref{def:threedetcrossprod} of \href{https://ximera.osu.edu/oerlinalg/LinearAlgebra/VEC-0080/main}{Cross Product and its Properties}.)
Define $T:\mathbb{M}_{3,3}\rightarrow \RR$ by $T(A)=\det(A)$.  

\begin{problem}\label{prob:detlintrans1}
Find $T\left(\begin{bmatrix}1&2&3\\4&5&6\\7&8&9\end{bmatrix}\right)$

Answer: $$T\left(\begin{bmatrix}1&2&3\\4&5&6\\7&8&9\end{bmatrix}\right)=\answer{0}$$
\end{problem}

\begin{problem}\label{prob:detlintrans2}
Is $T$ a linear transformation?  If so, prove it.  If not, give a counterexample.
\end{problem}
\end{problem}

\begin{problem}
Define $T:\mathbb{P}^3\rightarrow\mathbb{P}^2$ by $T(p(x))=p'(x)$.  (In other words, $T$ maps a polynomial to its derivative.)

\begin{problem}\label{prob:lintransderivative1}
Find $T(4x^3-2x^2+x+6)$.

Answer: $$T(4x^3-2x^2+x+6)=\answer{12}x^2-\answer{4}x+\answer{1}$$
\end{problem}

\begin{problem}\label{prob:lintransderivative2}
Is $T$ a linear transformation?  If so, prove it.  If not, give a counterexample.
\end{problem}
\end{problem}

% \begin{problem}
% Define $T:\mathbb{P}^2\rightarrow\mathbb{P}^3$ by $T(p(x))=xp(x)$.  

% \begin{problem}\label{prob:lintransmultbyx1}
% Find $T(-x^2+2x-4)$.

% Answer: $$T(-x^2+2x-4)=\answer{-x^3+2x^2-4x}$$
% \end{problem}

% \begin{problem}\label{prob:lintransmultbyx2}
% Is $T$ a linear transformation?  If so, prove it.  If not, give a counterexample.
% \end{problem}
% \end{problem}

\begin{problem}\label{prob:symmMatLinTrans}
Recall that the set $V$ of all symmetric $2\times 2$ matrices is a subspace of $\mathbb{M}_{2,2}$.  In Example \ref{ex:symmetricmatsubspace} of \href{https://ximera.osu.edu/oerlinalg/LinearAlgebra/VSP-0060/main}{Bases and Dimension of Abstract Vector Spaces} we demonstrated that $\mathcal{B} = \left\{
\begin{bmatrix}
1 & 0 \\
0 & 0
\end{bmatrix}, \begin{bmatrix}
0 & 0 \\
0 & 1
\end{bmatrix}, \begin{bmatrix}
0 & 1 \\
1 & 0
\end{bmatrix}
\right\}$ is a basis for $V$.  Define $T:V\rightarrow \RR^3$ by $T(A)=[A]_{\mathcal{B}}$.  Find $T(I_2)$ and $T\left(\begin{bmatrix}2&-3\\-3&1\end{bmatrix}\right)$.

Answer:
$$T(I_2)=\begin{bmatrix}\answer{1}\\\answer{1}\\\answer{0}\end{bmatrix}$$
$$T\left(\begin{bmatrix}2&-3\\-3&1\end{bmatrix}\right)=\begin{bmatrix}\answer{2}\\\answer{1}\\\answer{-3}\end{bmatrix}$$
\end{problem}

\begin{problem}\label{prob:coordvector}
Let $V$ be a subspace of $\RR^3$ with a basis $\mathcal{B}=\left\{\begin{bmatrix}2\\1\\-1\end{bmatrix}, \begin{bmatrix}0\\3\\2\end{bmatrix}\right\}$.  Find the coordinate vector, $[\vec{v}]_{\mathcal{B}}$, for $\vec{v}=\begin{bmatrix}4\\-1\\-4\end{bmatrix}$.
$$[\vec{v}]_{\mathcal{B}}=\begin{bmatrix}\answer{2}\\\answer{-1}\end{bmatrix}$$
\end{problem}

\begin{problem}\label{prob:switchbasisorder}
If the order of the basis elements in Problem \ref{prob:coordvector} was switched to form a new basis
$$\mathcal{B}'=\left\{\begin{bmatrix}0\\3\\2\end{bmatrix}, \begin{bmatrix}2\\1\\-1\end{bmatrix} \right\}$$
How would this affect the coordinate vector?

$$[\vec{v}]_{\mathcal{B}'}=\begin{bmatrix}\answer{-1}\\\answer{2}\end{bmatrix}$$
\end{problem}



\begin{problem}\label{prob:polylintranscoordvect} In Practice Problem \ref{prob:linindabstractvsp123} of \href{https://ximera.osu.edu/oerlinalg/LinearAlgebra/VSP-0060/main}{Bases and Dimension of Abstract Vector Spaces} you demonstrated that
$\mathcal{B}=\{x^{2}, x + 1, 1 - x - x^{2}\}$ is a basis for $\mathbb{P}^2$.  Define $T:\mathbb{P}^2\rightarrow \RR^3$ by $T(p(x))=[p(x)]_{\mathcal{B}}$.  Find $T(0)$, $T(x+1)$ and $T(x^2-3x+1)$.

Answer:
$$T(0)=\begin{bmatrix}\answer{0}\\\answer{0}\\\answer{0}\end{bmatrix}$$
$$T(x+1)=\begin{bmatrix}\answer{0}\\\answer{1}\\\answer{0}\end{bmatrix}$$
$$T(x^2-3x+1)=\begin{bmatrix}\answer{3}\\\answer{-1}\\\answer{2}\end{bmatrix}$$
\end{problem}

% \begin{problem}
% Let $$\vec{v}_1=\begin{bmatrix}1\\3\\0\end{bmatrix},\quad \vec{v}_2=\begin{bmatrix}0\\1\\-2\end{bmatrix}$$
% $$\vec{w}_1=\begin{bmatrix}1\\-1\\4\end{bmatrix},\quad \vec{w}_2=\begin{bmatrix}0\\2\\-1\end{bmatrix}$$

% Let $V=\text{span}(\vec{v}_1, \vec{v}_2)$ and $W=\text{span}(\vec{w}_1, \vec{w}_2)$.

% Suppose $T:V\rightarrow W$ is a linear transformation such that 
% $$T(\vec{v}_1)=\begin{bmatrix}2\\0\\7\end{bmatrix},\quad T(\vec{v}_2)=\begin{bmatrix}-1\\7\\1\end{bmatrix}$$
%   \begin{problem}\label{prob:lintransandbasis1}
%   Verify that vectors $\begin{bmatrix}2\\0\\7\end{bmatrix}$ and $\begin{bmatrix}-1\\7\\1\end{bmatrix}$ are in $W$ by expressing each as a linear combination of $\vec{w}_1$ and $\vec{w}_2$.
%   $$\begin{bmatrix}2\\0\\7\end{bmatrix}=\answer{2}\vec{w}_1+\answer{1}\vec{w}_2$$
%   $$\begin{bmatrix}-1\\7\\1\end{bmatrix}=\answer{-1}\vec{w}_1+\answer{3}\vec{w}_2$$
%   \end{problem}
  
%   \begin{problem}\label{prob:lintransandbasis2}
%   Show that $\vec{v}=\begin{bmatrix}1\\2\\2\end{bmatrix}$ is in $V$ by expressing it as a linear combination of $\vec{v}_1$ and $\vec{v}_2$.
%   $$\vec{v}=\answer{1}\vec{v}_1+\answer{-1}\vec{v}_2$$
%   \end{problem}
  
%   \begin{problem}\label{prob:lintransandbasis3}
%   Find $T(\vec{v})$ and express it as a linear combination of $\vec{w}_1$ and $\vec{w}_2$.
%   $$T(\vec{v})=\answer{3}\vec{w}_1+\answer{-2}\vec{w}_2$$
%   \end{problem}
%   \end{problem}


\begin{problem}\label{prob:lintransandbasis4} Let $V$ and $W$ be vector spaces, and let $\mathcal{B}_V=\{\vec{v}_1, \vec{v}_2, \vec{v}_3, \vec{v}_4\}$ and $\mathcal{B}_W=\{\vec{w}_1,\vec{w}_2, \vec{w}_3\}$ be ordered bases of $V$ and $W$, respectively.  Suppose $T:V\rightarrow W$ is a linear transformation such that: $$T(\vec{v}_1)=\vec{w}_2$$ $$T(\vec{v}_2)=2\vec{w}_1-3\vec{w}_2$$
$$T(\vec{v}_3)=\vec{w}_2+\vec{w}_3$$
$$T(\vec{v}_4)=-\vec{w}_1$$
If $\vec{v}=-2\vec{v}_1+3\vec{v}_2-\vec{v}_4$, express $T(\vec{v})$ as a linear combination of vectors of $\mathcal{B}_W$.
$$T(\vec{v})=\answer{7}\vec{w}_1-\answer{11}\vec{w}_2+\answer{0}\vec{w}_3$$
Find $[\vec{v}]_{\mathcal{B}_V}$ and $[T(\vec{v})]_{\mathcal{B}_{W}}$
$$[\vec{v}]_{\mathcal{B}_V}=\begin{bmatrix}\answer{-2}\\\answer{3}\\\answer{0}\\\answer{-1}\end{bmatrix},\quad [T(\vec{v})]_{\mathcal{B}_{W}}=\begin{bmatrix}\answer{7}\\\answer{-11}\\\answer{0}\end{bmatrix}$$
\end{problem}



\begin{problem}\label{prob:completeproofoflin}
Complete the proof of Theorem \ref{th:coordvectmappinglinear}.
\end{problem}


\end{document}
