\documentclass{ximera}
\input{../preamble.tex}

 \title{Finding the Determinant} \license{CC BY-NC-SA 4.0}

\begin{document}

\begin{abstract}

\end{abstract}
\maketitle

\begin{onlineOnly}
\section*{Finding the Determinant}
\end{onlineOnly}

In this section we will define a function that assigns to each square matrix $A$ a scalar output called the \dfn{determinant of $A$}.  We will denote the determinant of $A$ by $\det{A}$.  For a matrix with real number entries, the output of the determinant function will always be a real number.

One important property of the determinant is its connection to matrix inverses.  We will find that a matrix $A$ is singular if and only if $\det{A}=0$.  For nonsingular matrices, we will establish a formula that gives the inverse of a matrix exclusively in terms of determinants.  This property will be addressed in detail in \href{https://ximera.osu.edu/oerlinalg/LinearAlgebra/DET-0040/main}{Poperties of the Determinant}, and \href{https://ximera.osu.edu/oerlinalg/LinearAlgebra/DET-0060/main}{Determinants and Inverses of Nonsingular Matrices}.

Geometrically speaking, the determinant of a matrix of a linear transformation is the factor by which the area (or volume or hypervolume) is scaled by the transformation.  This will be discussed in \href{https://ximera.osu.edu/oerlinalg/LinearAlgebra/DET-0070/main}{Determinants as Areas and Volumes}. 

\subsection*{Cofactor Expansion Along the Top Row}
To start from the beginning, let us define the determinant of a $1\times 1$ matrix.

\begin{definition}\label{def:onebyonedet} Let
$A=\begin{bmatrix}a\end{bmatrix}$.  Define the \dfn{determinant} of $A$ by $\det{A}=a$.
\end{definition}
It is important to note that this definition is consistent with our goal of making a connection between determinants and invertibility.  Observe that $A^{-1}=\begin{bmatrix}a^{-1}\end{bmatrix}$ exists if and only if $a\neq 0$.

Now we proceed to $2\times 2$ matrices.  According to Formula \ref{form:detinverse}, the inverse of a nonsingular matrix $A=\begin{bmatrix}a&b\\c&d\end{bmatrix}$ is given by
$$A^{-1}=\frac{1}{ad-bc}\begin{bmatrix}d&-b\\-c&a\end{bmatrix}$$
Observe that $A^{-1}$ exists if and only if $ad-bc\neq 0$.  We will call the number $ad-bc$ the determinant of $A$.

\begin{definition}\label{def:twobytwodet}
Let $A=\begin{bmatrix}a&b\\c&d\end{bmatrix}$.  The determinant of $A$ is defined by 
\begin{equation}\label{eq:twobytwodet}\det{A}=\det{\begin{bmatrix}a&b\\c&d\end{bmatrix}}=\begin{vmatrix}a&b\\c&d\end{vmatrix}=ad-bc\end{equation}
\end{definition}
Note the distinction between the square bracket notation associated with the matrix $\begin{bmatrix}a&b\\c&d\end{bmatrix}$ and the vertical bar notation $\begin{vmatrix}a&b\\c&d\end{vmatrix}$ used to denote  the determinant in expression (\ref{eq:twobytwodet}).

\begin{example}\label{ex:2x2det}
$$\det{\begin{bmatrix}1&2\\3&4\end{bmatrix}}=\begin{vmatrix}1&2\\3&4\end{vmatrix}=(1)(4)-(2)(3)=-2$$
\end{example}

The easiest way to understand the definition of the determinant for a $3\times 3$ matrix is to start with an example.

\begin{example}\label{ex:threebythreedet1}
Find $\det{A}$ if 
$$A=\begin{bmatrix}3&-2&1\\5&-1&2\\1&4&1\end{bmatrix}$$
\begin{explanation}
\begin{align*}
\det{A}&=(3)\begin{vmatrix}-1&2\\4&1\end{vmatrix}-(-2)\begin{vmatrix}5&2\\1&1\end{vmatrix}+(1)\begin{vmatrix}5&-1\\1&4\end{vmatrix}\\
&=(3)(-1-8)-(-2)(5-2)+(1)(20+1)\\
&=-27+6+21\\
&=0
\end{align*}

\youtube{aR2w-viFcvI}
\end{explanation}
\end{example}

We now formalize what we learned in Example \ref{ex:threebythreedet1}.

\begin{definition}\label{def:threebythreedet}
Let
$$A=\begin{bmatrix}a&b&c\\d&e&f\\g&h&i\end{bmatrix}$$
The \dfn{determinant} of $A$ is given by
\begin{align}\label{eq:det3by3}
\det{A}=|A|&=a\begin{vmatrix}e&f\\h&i\end{vmatrix}-b\begin{vmatrix}d&f\\g&i\end{vmatrix}+c\begin{vmatrix}d&e\\g&h\end{vmatrix}
\end{align}
\end{definition}

We will now reiterate several important features of this definition and introduce some vocabulary:
\begin{itemize}
\item The coefficients $a$, $b$ and $c$ are the entries of the first row of matrix $A$.  Coefficients in the formula follow an alternating sign pattern: $+a$, $-b$, $+c$.  This pattern will persist in the determinant formulas for determinants of larger matrices.
\item When using equation (\ref{eq:det3by3}), we compute determinants of three matrices:
$$\begin{bmatrix}e&f\\h&i\end{bmatrix},\quad \begin{bmatrix}d&f\\g&i\end{bmatrix},\quad \begin{bmatrix}d&e\\g&h\end{bmatrix}$$
These matrices are called \dfn{minor} matrices.  To form each minor matrix,
cross out the row and column that the corresponding coefficient is in.  For example, the minor matrix corresponding to coefficient $b$ is found by crossing out the row and column that $b$ is in.
\begin{center}
\begin{tikzpicture}
  \matrix (m)[
    matrix of math nodes,
    nodes in empty cells,
    left delimiter={[},right delimiter={]},minimum width=width("a"),minimum height=height("b")] {
    a    & {\color{red}b}  & c  \\
    d & e   & f   \\
    g   & h    & i     \\
  } ;

  %\draw (m-3-2.south west) rectangle (m-2-3.north east);
  \draw[blue](m-1-1.west) -- (m-1-1.east);
   \draw[blue](m-1-3.west) -- (m-1-3.east);
  \draw[blue](m-2-2.north) -- (m-3-2.south);
 \end{tikzpicture}
 \end{center} 
 \item The process for finding the determinant described in Definition \ref{def:threebythreedet} is referred to as a \dfn{cofactor expansion along the top row}. % we will explain this term in more detail in \href{https://ximera.osu.edu/oerlinalg/LinearAlgebra/DET-0050/main}{Proof of the Laplace Expansion Theorem}.
\end{itemize}


\begin{example}\label{ex:3x3det2}
Find $\det{A}$ if 
$$A=\begin{bmatrix}4&3&-2\\1&-5&3\\-4&1&1\end{bmatrix}$$
\begin{explanation}
$$
\det{A}=(4)\begin{vmatrix}\answer{-5}&\answer{3}\\\answer{1}&\answer{1}\end{vmatrix}-(3)\begin{vmatrix}\answer{1}&\answer{3}\\\answer{-4}&\answer{1}\end{vmatrix}+(-2)\begin{vmatrix}\answer{1}&\answer{-5}\\\answer{-4}&\answer{1}\end{vmatrix}
=\answer{-33}
$$
\end{explanation}
\end{example}

We are starting to observe a certain pattern in the process of computing the determinant.  This pattern will persist for larger matrices.  Let's take a look at a $4\times 4$ matrix.

\begin{example}\label{ex:4by4withVideo}
    Find $\det{A}$ if 
    $$A=\begin{bmatrix} 2 & 3 & -2 & -5\\0 & 1& -2& 0\\1& 3 & 0 &-1\\2&0& 1&1\end{bmatrix}$$

\begin{explanation}
As you watch the video below, pay particular attention to the same patterns as you saw in the case of $3\times 3$ matrices: the alternating sign pattern and the process of forming minor matrices.

\begin{align*}
\det{A}
&=2\begin{vmatrix}1& -2& 0\\3 & 0 &-1\\0& 1&1\end{vmatrix}-3\begin{vmatrix}0 & -2& 0\\1 & 0 &-1\\2& 1&1\end{vmatrix}-2\begin{vmatrix}0 & 1& 0\\1& 3 &-1\\2&0&1\end{vmatrix}-(-5)\begin{vmatrix}0 & 1& -2\\1& 3 & 0 \\2&0& 1\end{vmatrix}\\
&=2(7)-3(6)-2(-3)+5(11)\\
&=57
\end{align*}

\youtube{YIJq7TqncyU}
\end{explanation}
\end{example}

\begin{example}\label{ex:expansiontoprow}
Find $\det{A}$ if 
$$A=\begin{bmatrix}4&-1&2&1\\3&0&1&-2\\
2&1&5&1\\-2&1&3&-1\end{bmatrix}$$
\begin{explanation}
We will use the entries in the top row as coefficients in front of $3\times 3$ determinants.  As before, we will use the alternating sign pattern for the coefficients:
$$+(4), -(-1), +(2), -(1)$$
Just like in the case of a $3 \times 3$ matrix in Example \ref{ex:threebythreedet1}, each of the smaller determinants is obtained by crossing out the row and the column where the coefficient is located.
\begin{align*}
\det{A}
&=4\begin{vmatrix}0&1&-2\\1&5&1\\1&3&-1\end{vmatrix}+\begin{vmatrix}3&1&-2\\2&5&1\\-2&3&-1\end{vmatrix}+2\begin{vmatrix}3&0&-2\\2&1&1\\-2&1&-1\end{vmatrix}-\begin{vmatrix}3&0&1\\2&1&5\\-2&1&3\end{vmatrix}\\&=4(\answer{6})+(\answer{-56})+2(\answer{-14})-(\answer{-2})\\
&=\answer{-58}
\end{align*}
\end{explanation}
\end{example}

\subsection*{Cofactor Expansion Along the First Column}
We defined the determinant of a matrix in terms of cofactor expansion along the top row.  We will now see what happens when we expand along the first \textit{column} instead.  We will refer to this process as \dfn{cofactor expansion along the first column}.  Surprisingly, both expansions yield the same result.  To illustrate this, let's revisit Examples \ref{ex:threebythreedet1} and \ref{ex:expansiontoprow}. 

\begin{example}\label{init:expansionfirstcol1}
Let 
$$A=\begin{bmatrix}3&-2&1\\5&-1&2\\1&4&1\end{bmatrix}$$
In Example \ref{ex:threebythreedet1} we found that $\det{A}=0$.  Let's try to mimic what we did earlier, but instead of expanding along the first row, we will expand along the fist column.  
\begin{align*}
&(3)\begin{vmatrix}-1&2\\4&1\end{vmatrix}-(5)\begin{vmatrix}-2&1\\4&1\end{vmatrix}+(1)\begin{vmatrix}-2&1\\-1&2\end{vmatrix}\\
&=(3)(-1-8)-(5)(-2-4)+(1)(-4+1)\\
&=-27+30-3\\
&=0\\
&=\det{A}
\end{align*}
\end{example}

Let's go through this process again for a larger matrix.

\begin{exploration}\label{init:expansionfirstcol2}
Let
$$A=\begin{bmatrix}4&-1&2&1\\3&0&1&-2\\
2&1&5&1\\-2&1&3&-1\end{bmatrix}$$
In Example \ref{ex:expansiontoprow} we found that $\det{A}=-58$.  We will now try to expand along the fist column.  

When computing determinants of the four $3\times 3$ matrices below, try different approaches.  You might want to expand along the first row for some of them, and along the first column for others.  Looking for where zeros are located will help you decide what to try.
\begin{align*}
&4\begin{vmatrix}0&1&-2\\1&5&1\\1&3&-1\end{vmatrix}-3\begin{vmatrix}-1&2&1\\1&5&1\\1&3&-1\end{vmatrix}+2\begin{vmatrix}-1&2&1\\0&1&-2\\1&3&-1\end{vmatrix}-(-2)\begin{vmatrix}-1&2&1\\0&1&-2\\1&5&1\end{vmatrix}\\
&=4(\answer{6})-3(\answer{10})+2(\answer{-10})+2(\answer{-16})\\
&=\answer{-58}\\
&=\det{A}
\end{align*}
\end{exploration}

In Example \ref{init:expansionfirstcol1} and Exploration \ref{init:expansionfirstcol2} we were careful not to claim at the outset that we were finding the determinant of the matrix by cofactor expansion along the first column; we merely observed that the resulting value was equal to the determinant.  It is possible to prove that both expansions produce the same result (Theorem \ref{th:rowcolexpequivalence}).  Therefore the determinant of a matrix can be defined in terms of cofactor expansion along the first row or column.  

\subsection*{Cofactor Expansion Along Any Row or Column}

We originally defined the determinant of a matrix via expansion along the top row of the matrix.  We later observed that expansion along the first column produces the same result.  It turns out that the value of the determinant can be computed by expanding along any row or column.  This result is known as the \dfn{Laplace Expansion Theorem} (\ref{th:laplace1}).

When expanding along an arbitrary row or column, we will continue to follow the two patterns we observed earlier.
\begin{itemize}
    \item The alternating sign pattern for coefficients will follow the checkerboard pattern below.
 $$\begin{bmatrix}+&-&+&-&+&\ldots\\-&+&-&+&-&\ldots\\
 +&-&+&-&+&\ldots\\-&+&-&+&-&\ldots\\\vdots &\vdots  & \vdots & \vdots &\vdots &\ddots \end{bmatrix}$$
 \item Minor matrices will be formed by eliminating the row and column that the corresponding coefficient is in.
\end{itemize}

To illustrate this, let's take another look at matrix $A$ from Example \ref{ex:expansiontoprow}. 


 \begin{example}\label{ex:laplace1}
Let  
$$A=\begin{bmatrix}4&-1&2&1\\3&0&1&-2\\
2&1&5&1\\-2&1&3&-1\end{bmatrix}$$
Follow the rules described above to expand along the second row.  Compare your result with the determinant you found in Example \ref{ex:expansiontoprow}.
\begin{explanation}

 The second row has the advantage over other rows in that it contains a zero.  This will simplify our calculations.  Following the checkerboard sign pattern along the second row we get

\begin{align*}
\det{A}
&=-3\begin{vmatrix}-1&2&1\\1&5&1\\1&3&-1\end{vmatrix}-\begin{vmatrix}4&-1&1\\2&1&1\\-2&1&-1\end{vmatrix}+(-2)\begin{vmatrix}4&-1&2\\2&1&5\\-2&1&3\end{vmatrix}\\&=-3(\answer{10})-(\answer{-4})-2(\answer{16})\\
&=\answer{-58}
\end{align*}
This answer is the same as the answer we got using expansion along the first row in Example \ref{ex:expansiontoprow}.
    
\end{explanation}
 \end{example}
 
It is clear that having zeros as entries in the matrix reduces the number of computations necessary to find the determinant.  The following example demonstrates how to use zeros to our advantage.

\begin{example}\label{ex:laplace2}
Find $\det{A}$ if
$$A=\begin{bmatrix}4&0&0&0&2\\0&-1&1&0&0\\2&0&0&-5&3\\0&1&4&0&-1\\1&1&5&0&0\end{bmatrix}$$

\begin{explanation}
The fourth column contains the most zeros, so we will expand along that column.  The  $(3, 4)$-entry is the only non-zero entry in the fourth column.  Following the checkerboard pattern, we see that the sign in front of $-5$ is a minus.  
$$\det{A}=-(-5)\begin{vmatrix}4&0&0&2\\0&-1&1&0\\0&1&4&-1\\1&1&5&0\end{vmatrix}
$$
Next we will expand the minor matrix along the top row.
$$\det{A}=5\left(4\begin{vmatrix}-1&1&0\\1&4&-1\\1&5&0\end{vmatrix}-2\begin{vmatrix}0&-1&1\\0&1&4&\\1&1&5\end{vmatrix}\right)$$
Try the next step on your own.  We suggest that you expand the first matrix along the last column and expand the second matrix along the first column.
$$\det(A)=5\big(4(\answer{-6})-2(\answer{-5})\big)=\answer{-70}$$
\end{explanation}
\end{example}

\subsection*{A Note on Equivalency}
We initially introduced the determinant of a matrix via cofactor expansion along the top row.  We later observed that cofactor expansion along any row or column produces the same result.  We have to be careful, however, not to use a few examples as ``proof" that all cofactor expansions are equivalent.  Such claims need to be carefully supported with general proofs.  Unfortunately, in this case, the proofs are tedious and conceptually unenlightening.  An interested reader can find them in \href{https://ximera.osu.edu/oerlinalg/LinearAlgebra/DET-0050/main}{Tedious Proofs Concerning Determinants}.

\subsection*{Determinants of Some Special Matrices}
We know that we can find the determinant of a matrix by cofactor expansion along the top row or the first column.  (See Theorem \ref{th:rowcolexpequivalence} of \href{https://ximera.osu.edu/oerlinalg/LinearAlgebra/DET-0050/main}{Tedious Proofs Concerning Determinants} for proof.)  This property gives rise to a useful result.
\begin{theorem}\label{th:detoftrans}
Let $A$ be a square matrix, then
$$\det{A^T}=\det{A}$$
\end{theorem}
\begin{proof}
    See Practice Problem \ref{prob:detOfTrans}.
\end{proof}

As we observed earlier, having zeros in a matrix makes it easier for us to compute its determinant.  Recall that that a square matrix is \dfn{upper-triangular} if all of the entries below the main diagonal are zero.  Similarly, a square matrix is called \dfn{lower-triangular} if all of the entries above the main diagonal are zero.  Together, upper and lower triangular matrices are categorized as \dfn{triangular} matrices.

\begin{theorem}\label{lemma:triangulardet}
If $A$ is a triangular matrix, then $\det{A}$ is equal to the product of its diagonal entries.
\end{theorem}
\begin{proof}
We proceed by induction on $n$, where $A$ is an $n\times n$ matrix.  It is easy to see that this result holds for $n=1, 2$.  Suppose that the result holds for $(n-1)\times (n-1)$ triangular matrices.  We need to show that it holds for $n\times n$ triangular matrices.  

Suppose $A=[a_{ij}]$ is a triangular matrix. Then, with the exception of $a_{11}$, the entries in the first row (or column) of $A$ are guaranteed to be zeros.
  We will take advantage of these zeros and expand along the first row (or column) of $A$.  As we do so, we obtain a single product of $a_{11}$ and the determinant of a minor matrix obtained by crossing out the first row and column of $A$.  But this minor $(n-1)\times (n-1)$ matrix is also a triangular matrix with diagonal etries $a_{22}, a_{33},\ldots, a_{nn}$.  By induction hypothesis, its determinant is equal to the product of its diagonal entries, $a_{22}\cdot a_{33}\cdot\ldots\cdot a_{nn}$.  Therefore $$\det{A}=a_{11}(a_{22}\cdot a_{33}\cdot\ldots\cdot a_{nn})$$
 This completes the proof.
\end{proof}

As an immediate consequence of this theorem, we have the following result.

\begin{corollary}\label{lemma:detofid} Let $I$ be the identity matrix, then
 $$\det{I}=1$$
 \end{corollary}

 We first introduced block matrices in \href{https://ximera.osu.edu/oerlinalg/LinearAlgebra/MAT-0023/main}{Block Matrix Multiplication}.  Matrices of the form $\begin{bmatrix}A & C\\O& B\end{bmatrix}$ and $\begin{bmatrix}A & O\\D& B\end{bmatrix}$, where $A$, $B$ are square matrices and $O$ is the zero matrix, are said to be \dfn{block triangular}.  The following theorem makes it easy to compute determinants of such matrices.

 \begin{theorem}\label{th:blockTriDet}
     Consider block triangular matrices $\begin{bmatrix}A & C\\O& B\end{bmatrix}$ and $\begin{bmatrix}A & O\\D& B\end{bmatrix}$, where $A$ and $B$ are square matrices.  Then
     $$\det{\begin{bmatrix}A & C\\O& B\end{bmatrix}}=\det{A}\det{B}\quad\mbox{and}\quad\det{\begin{bmatrix}A & O\\D& B\end{bmatrix}}=\det{A}\det{B}$$
 \end{theorem}
\begin{proof}
    Write $T=\begin{bmatrix}A & C\\O& B\end{bmatrix}$ and proceed by induction on $k$, where $A$ is $k\times k$.  If $k=1$, then the result follows from cofactor expansion along the first column.  In general, let $S_i(T)$ denote the matrix obtained from $T$ by deleting row $i$ and column 1. Then the cofactor expansion along the first column is
    $$\det{T}=a_{11}\det{S_1(T)}-a_{21}\det{S_2(T)}+\dots + (-1)^{k+1}\det{S_k(T)}$$
    where $a_{11}, a_{21},\dots , a_{k1}$ are the entries in the first column of $A$.  Observe that 
    $$S_i(T)=\begin{bmatrix}S_i(A) & C_i\\O& B\end{bmatrix}$$
    where $i=1,2,\dots , k$, $S_i(A)$ denotes matrix $A$ with column 1 and row $i$ deleted, and $C_i$ denotes matrix $C$ with with row $i$ deleted.
    
    Since $S_i(A)$ is a $(k-1)\times (k-1)$ matrix, by the induction hypothesis,
    $$\det{S_i(T)}=\det{S_i(A)}\cdot \det{B}$$
    This gives us
    \begin{align*}
        \det{T}=&a_{11}\det{S_1(T)}-a_{21}\det{S_2(T)}+\dots + (-1)^{k+1}a_{k1}\det{S_k(T)}\\
        =&a_{11}\det{S_1(A)}\cdot\det{B}-a_{21}\det{S_2(A)}\cdot\det{B}+\dots \\
        &\dots+ (-1)^{k+1}a_{k1}\det{S_k(A)}\cdot\det{B}\\
        =&\Big(a_{11}\det{S_1(A)}-a_{21}\det{S_2(A)}+\dots + (-1)^{k+1}a_{k1}\det{S_k(A)}\Big)\det{B}\\
        =&\det{A}\det{B}
    \end{align*}
    The lower triangular case is similar.
\end{proof}

\begin{example}\label{ex:blockTriDet}
    Find $\det{A}$ if 
    $$A=\begin{bmatrix}2&1&3&3\\1&-1&-2&1\\0&0&1&1\\0&0&4&1\end{bmatrix}$$
  \begin{explanation}
      $$\begin{vmatrix}2&1&3&3\\1&-1&-2&1\\0&0&1&1\\0&0&4&1\end{vmatrix}=\begin{vmatrix}2&1\\1&-1\end{vmatrix}\begin{vmatrix}1&1\\4&1\end{vmatrix}=\answer{9}$$
  \end{explanation}  
\end{example}


\section*{Practice Problems}

\emph{Problems \ref{prob:2x2det1}-\ref{prob:laplace}}
Find the determinant of each matrix.

  \begin{problem}\label{prob:2x2det1}
  $$A=\begin{bmatrix}4&-2\\3&7\end{bmatrix}$$
  Answer:
  $$\det{A}=\answer{34}$$
  \end{problem}
  
  \begin{problem}\label{prob:2x2det2}
  $$B=\begin{bmatrix}5&-1&0\\0&3&-2\\1&-1&2\end{bmatrix}$$
  Answer:
  $$\text{det}(B)=\answer{22}$$
  \end{problem}

  \begin{problem}\label{prob:laplace}
  $$C=\begin{bmatrix}1&-2&0&0&0\\0&-4&1&1&0\\3&0&-1&0&1\\0&0&4&1&0\\-1&-2&0&0&0\end{bmatrix}$$
   Answer:
  $$\det(C)=\answer{12}$$
 \end{problem}


\begin{problem}\label{prob:toprowexp2x2}
Show that Definition \ref{def:toprowexpansion} is consistent with Definition \ref{def:twobytwodet} by verifying that both produce the same result when applied to a $2\times 2$ matrix.
\end{problem}

\begin{problem}\label{prob:detOfTrans}
    Prove Theorem \ref{th:detoftrans}.
\end{problem}

\begin{problem}\label{prob:detrowswitch}
Let $B'$ be a matrix obtained from $B$ of Problem \ref{prob:2x2det2} by switching the first and the second row of $B$.  Compute the determinant of $B'$.  What do you observe?
\end{problem}

\begin{problem}\label{prob:2x2rowswitchproof}
Make a conjecture about what happens to the determinant of a matrix if two rows of a matrix are switched.  Prove your conjecture for a $2\times 2$ matrix.
\end{problem}

\begin{problem}\label{prob:scalarmultrowdet} Let $B'$ be a matrix obtained from $B$ of Problem \ref{prob:2x2det2} by multiplying the middle row by $-3$.  Compute the determinant of $B'$.  What do you observe?
\end{problem}

\begin{problem}\label{prob:rowtimesconstant2x2proof}
Make a conjecture about what happens to the determinant of a matrix if one of the rows is multiplied by a constant.  Prove your conjecture for a $2\times 2$ matrix.
\end{problem}

\begin{problem}\label{prob:matrixtimesconst}
Let $B'$ be a matrix obtained from $B$ of Problem \ref{prob:2x2det2} by multiplying $B$ by $2$.  Compute the determinant of $B'$.  What do you observe?
\end{problem}

\begin{problem}\label{prob:matrixtimesconstant2x2proof}
Make a conjecture about what happens to the determinant of a matrix if the matrix is multiplied by a constant.  Prove your conjecture for a $2\times 2$ matrix.
\end{problem}

\begin{problem}\label{prob:scalarmultofrow}
Let $B'$ be a matrix obtained from $B$ of Problem \ref{prob:2x2det2} by adding twice the third row to the first.  Compute the determinant of $B'$.  What do you observe?
\end{problem}

\begin{problem}\label{prob:scalarmultofrow2x2}
Make a conjecture about what happens to the determinant of a matrix if a multiple of one row is added to another row.  Prove your conjecture for a $2\times 2$ matrix.
\end{problem}

\begin{problem}\label{prob:detsumsumdetquestion}
Is it true that 
$\det{(A+B)}=\det{A}+\det{B}$?
\end{problem}

\section*{Text Source}
The text in this section partially comes from Section 3.1  of Keith Nicholson's \href{https://open.umn.edu/opentextbooks/textbooks/linear-algebra-with-applications}{\it Linear Algebra with Applications} (CC-BY-NC-SA).

\end{document} 