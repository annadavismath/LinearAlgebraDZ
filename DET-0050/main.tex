\documentclass{ximera}
\input{../preamble.tex}

\title{Tedious Proofs Concerning Determinants} \license{CC BY-NC-SA 4.0}

\begin{document}

\begin{abstract}

\end{abstract}
\maketitle


\section*{Tedious Proofs Concerning Determinants}
In \href{https://ximera.osu.edu/oerlinalg/LinearAlgebra/DET-0010/main}{Finding the Determinant} we described the determinant as a function that assigns a scalar to every square matrix.  The value of the function in the original definition was given by cofactor expansion along the first row of the matrix.  We also observed, through examples, that cofactor expansion along any row or column produces the same value.  Examples, however, do not constitute a sufficient proof of equivalency of different cofactor expansions.  In this section we will prove that cofactor expansions along any row or column produce the same outcome.  This result is known as the Laplace Expansion Theorem.  We will also prove several results concerning elementary row operations.

\subsection*{Cofactor Expansion Along the Top Row}
Let 
$$A=\begin{bmatrix}a&b&c\\d&e&f\\g&h&i\end{bmatrix}$$

Definition \ref{def:threebythreedet} of cofactor expansion along the top row for a $3\times 3$ matrix requires three \dfn{minor} matrices associated with $A$.  
\begin{itemize}
\item $A_{11}$ is obtained from $A$ by deleting the first row and the first column of $A$.
\begin{center}
\begin{tikzpicture}
  \matrix (m)[
    matrix of math nodes,
    nodes in empty cells,
    left delimiter={[},right delimiter={]},minimum width=width("a"),minimum height=height("b")] {
    a    & b  & c  \\
    d & e   & f   \\
    g   & h    & i     \\
  } ;

  \draw (m-3-2.south west) rectangle (m-2-3.north east);
  %\draw[blue](m-1-2.west) -- (m-1-3.east);
  %\draw[blue](m-2-1.north) -- (m-3-1.south);
 \end{tikzpicture}
 \end{center} 
 $$A_{11}=\begin{bmatrix}e&f\\h&i\end{bmatrix}$$
 \item $A_{12}$ is obtained from $A$ by deleting the first row and the second column of $A$.
 \begin{center}
\begin{tikzpicture}
  \matrix (m)[
    matrix of math nodes,
    nodes in empty cells,
    left delimiter={[},right delimiter={]},minimum width=width("a")] {
    a    & b  & c  \\
    d & e   & f   \\
    g   & h    & i     \\
  } ;
\draw (m-3-1.south west) rectangle (m-2-1.north east);
  \draw (m-3-3.south west) rectangle (m-2-3.north east);
 \end{tikzpicture}
 \end{center} 
 $$A_{12}=\begin{bmatrix}d&f\\g&i\end{bmatrix}$$
 \item $A_{13}$ is obtained from $A$ by deleting the first row and the third column of $A$.
 \begin{center}
\begin{tikzpicture}
  \matrix (m)[
    matrix of math nodes,
    nodes in empty cells,
    left delimiter={[},right delimiter={]},minimum width=width("a")] {
    a    & b  & c  \\
    d & e   & f   \\
    g   & h    & i     \\
  } ;
\draw (m-3-1.south west) rectangle (m-2-2.north east);
  
 \end{tikzpicture}
 \end{center} 
 $$A_{13}=\begin{bmatrix}d&e\\g&h\end{bmatrix}$$
\end{itemize}

The determinant of $A$ is given by
\begin{align*}\det{A}=|A|&=a\begin{vmatrix}e&f\\h&i\end{vmatrix}-b\begin{vmatrix}d&f\\g&i\end{vmatrix}+c\begin{vmatrix}d&e\\g&h\end{vmatrix}\\
&=a\big(\det{A_{11}}\big)-b\big(\det{A_{12}}\big)+c\big(\det{A_{13}}\big)
\end{align*}

Now we are ready for an $n\times n$ matrix.  Let 
$$A=\begin{bmatrix}a_{11} & a_{12} & \dots & a_{1j-1} & a_{1j} & a_{1j+1} & \dots & a_{1n}  \\
    a_{21} & a_{22} & \dots & a_{2j-1} & a_{2j} & a_{2j+1} & \dots & a_{2n}  \\
   \vdots & \vdots &  & \vdots & \vdots & \vdots &  & \vdots  \\
   a_{n1} & a_{n2} & \dots & a_{nj-1} & a_{nj} & a_{nj+1} & \dots & a_{nn}\end{bmatrix}$$
   Define $A_{1j}$ to be an $(n-1)\times (n-1)$ matrix obtained from $A$ by deleting the first row and the $j^{th}$ column of $A$.  We say that $A_{1j}$ is the \dfn{$(1, j)$-minor} of $A$.
\begin{center}
\begin{tikzpicture}
  \matrix (m)[
    matrix of math nodes,
    nodes in empty cells,
    left delimiter={[},right delimiter={]},minimum width=width("a22")] {
    a_{11} & a_{12} & \dots & a_{1j-1} & a_{1j} & a_{1j+1} & \dots & a_{1n}  \\
    a_{21} & a_{22} & \dots & a_{2j-1} & a_{2j} & a_{2j+1} & \dots & a_{2n}  \\
   \vdots & \vdots &  & \vdots & \vdots & \vdots &  & \vdots  \\
   a_{n1} & a_{n2} & \dots & a_{nj-1} & a_{nj} & a_{nj+1} & \dots & a_{nn}  \\
  } ;
\draw (m-4-1.south west) rectangle (m-2-4.north east);
\draw (m-4-6.south west) rectangle (m-2-8.north east);
 
 %\draw[blue](m-4-5.south) -- (m-2-5.north); 
 %\draw[blue](m-1-1.west) -- (m-1-4.east);
 %\draw[blue](m-1-6.west) -- (m-1-8.east);
 \end{tikzpicture}
 \end{center} 
For a $3\times 3$ matrix $A$ we have
$$\det{A}=a_{11}\big(\det{A_{11}}\big)-a_{12}\big(\det{A_{12}}\big)+a_{13}\big(\det{A_{13}}\big)$$
We want to follow the same pattern  to define the determinant of a larger matrix.  A distinct feature of this expression is the alternating sign pattern.  We want to preserve this feature as we increase matrix size. 

\begin{definition}\label{def:toprowexpansion}  Let $A=\begin{bmatrix}a_{ij}\end{bmatrix}$ be an $n\times n$ matrix.  Define the \dfn{determinant} of $A$ by
\begin{align*}\det{A}=(-1)^{1+1}a_{11}\det{A_{11}}&+(-1)^{1+2}a_{12}\det{A_{12}}+\ldots \\
\ldots &+(-1)^{1+j}a_{1j}\det{A_{1j}}+\ldots \\
\ldots &+(-1)^{1+n}a_{1n}\det{A_{1n}}\\
=\sum_{j=1}^n(-1)^{1+j}a_{1j}\det{A_{1j}}
\end{align*}
\end{definition}
Naturally, we would like to condense this formula.  To accomplish this, let
$$C_{1j}=(-1)^{1+j}\det{A_{1j}}$$
We will refer to $C_{1j}$ as the \dfn{$(1,j)$-cofactor of $A$}.  When we use the cofactor notation, the expression in Definition \ref{def:toprowexpansion} turns into the following:
$$\det{A}=a_{11}C_{11}+a_{12}C_{12}+\ldots +a_{1n}C_{1n}=\sum_{j=1}^n a_{1j}C_{1j}$$

This process of computing the determinant is called the \dfn{cofactor expansion along the first row}.  


\subsection*{Cofactor Expansion Along the First Column}
As we have observed in several examples in \href{https://ximera.osu.edu/oerlinalg/LinearAlgebra/DET-0010/main}{Finding the Determinant}, cofactor expansion along the first column produces the same result as cofactor expansion along the top row.  We will now formalize the process of cofactor expansion along the first column for an $n\times n$ matrix and prove that this process produces the same result as our original definition of the determinant.
Let $A$ be an $n\times n$ matrix. 
$$A=\begin{bmatrix}a_{11} & a_{12} & \dots  & a_{1n}  \\
    a_{21} & a_{22} &\dots  & a_{2n}  \\
   \vdots & \vdots &  & \vdots \\
   a_{i1} & a_{i2} & \dots  & a_{in}\\
   \vdots & \vdots &  & \vdots  \\
   a_{n1} & a_{n2} & \dots  & a_{nn}\end{bmatrix}$$
   Define $A_{i1}$ to be an $(n-1)\times (n-1)$ matrix obtained from $A$ by deleting the first column and the $i^{th}$ row of $A$.  We say that $A_{i1}$ is the \dfn{$(i, 1)$-minor} of $A$.
\begin{center}
\begin{tikzpicture}
  \matrix (m)[
    matrix of math nodes,
    nodes in empty cells,
    left delimiter={[},right delimiter={]},minimum width=width("a22")] {
    a_{11} & a_{12} & \dots  & a_{1n}  \\
    a_{21} & a_{22} &\dots  & a_{2n}  \\
   \vdots & \vdots &  & \vdots \\
   a_{i1} & a_{i2} & \dots  & a_{in}\\
   \vdots & \vdots &  & \vdots  \\
   a_{n1} & a_{n2} & \dots  & a_{nn}\\
  } ;
\draw (m-1-2.north west) rectangle (m-3-4.south east);
\draw (m-6-2.south west) rectangle (m-5-4.north east);
 \end{tikzpicture}
 \end{center} 
Define $C_{i1}=(-1)^{i+1}\det{A_{i1}}$ to be the
 \dfn{$(i,1)$-cofactor of $A$}.

\begin{definition}\label{def:firstcolexpansion1}  Let $A=\begin{bmatrix}a_{ij}\end{bmatrix}$ be an $n\times n$ matrix.  Define the \dfn{determinant} of $A$ by
\begin{align*}\det{A}=(-1)^{1+1}a_{11}\det{A_{11}}&+(-1)^{2+1}a_{21}\det{A_{21}}+\ldots \\
\ldots &+(-1)^{i+1}a_{i1}\det{A_{i1}}+\ldots \\
\ldots &+(-1)^{n+1}a_{n1}\det{A_{n1}}\\
=\sum_{i=1}^n(-1)^{i+1}a_{i1}\det{A_{i1}}
\end{align*}
or
$$\det{A}=a_{11}C_{11}+a_{21}C_{21}+\ldots +a_{n1}C_{n1}=\sum_{i=1}^n a_{i1}C_{i1}$$
\end{definition}

\subsubsection*{Proof of Definition Equivalence}
We will now show that cofactor expansion along the first row produces the same result as cofactor expansion along the first column.
\begin{theorem}\label{th:rowcolexpequivalence}
Let $A=\begin{bmatrix}a_{ij}\end{bmatrix}$ be an $n\times n$ matrix.  Then
$$\sum_{j=1}^n(-1)^{1+j}a_{1j}\det{A_{1j}}=\sum_{i=1}^n(-1)^{i+1}a_{i1}\det{A_{i1}}$$
\end{theorem}
\begin{proof}
We will proceed by induction on $n$.  Clearly, the result holds for $n=1$.  Just for practice you should also verify the equality for $n=2, 3$. (See Practice Problem \ref{prob:extrainductionsteps}.)  We will assume that the result holds for $(n-1)\times (n-1)$ matrices and show that it must hold for $n\times n$ matrices.

You will find the following matrix a useful reference as we proceed.

$$A=\begin{bmatrix}a_{11} & a_{12} & \dots &  a_{1j} &  \dots & a_{1n}  \\
    a_{21} & a_{22} & \dots &  a_{2j} &  \dots & a_{2n}  \\
   \vdots & \vdots &  & \vdots &   & \vdots  \\
  a_{i1} & a_{i2} & \ldots &  a_{ij} &  \ldots & a_{in}\\
  \vdots & \vdots &  & \vdots &   & \vdots  \\
   a_{n1} & a_{n2} & \dots &  a_{nj} &  \dots & a_{nn}\end{bmatrix}$$
   For convenience, we will refer to the Right-Hand Side (RHS) and the Left-Hand Side (LHS) of the equality we are trying to prove.
   $$\text{LHS}=\sum_{j=1}^n(-1)^{1+j}a_{1j}\det{A_{1j}}\overset{?}{=}\sum_{i=1}^n(-1)^{i+1}a_{i1}\det{A_{i1}}=\text{RHS}$$
   
   Note that the first term $a_{11}(-1)^{1+1}\det{A_{11}}$ is the same for LHS and RHS, so we will only need to consider $i,j\geq 2$.
   
We will start by analyzing RHS.  Consider an arbitrary entry $a_{i1}$ of the fist column.  This entry will only appear in the term $a_{i1}(-1)^{i+1}\det{A_{i1}}$. We will find $\det{A_{i1}}$ by cofactor expansion along the first row.  As we proceed, we have to pay special attention to the subscripts.  Because the first column of $A$ was removed, the $j^{th}$ column of $A$ contains the $(j-1)$ column of $A_{i1}$.  
\begin{align*}
&a_{i1}(-1)^{i+1}\det{A_{i1}}=\\
=&a_{i1}(-1)^{i+1}\Big(a_{12}(-1)^{1+1}\det{(A_{i1})_{11}}+\ldots +a_{1j}(-1)^{1+(j-1)}\det{(A_{i1})_{1(j-1)}}+\ldots \Big)
\end{align*}
Note that the entry $a_{1j}$ will only appear in the term $$a_{1j}(-1)^{1+(j-1)}\det{(A_{i1})_{1(j-1)}}$$
So, after we distribute $a_{i1}(-1)^{i+1}$, RHS will contain only one term of the form
$$a_{i1}a_{1j}(-1)^{p+q}\det{(A_{st})_{pq}}$$
We will perform a similar analysis on LHS.  Consider an arbitrary entry $a_{1j}$ of the fist row.  This entry will only appear in the term $a_{1j}(-1)^{1+j}\big(\det{A_{1j}}\big)$. Invoking the induction hypothesis, we will find $\det{A_{1j}}$ by cofactor expansion along the first column.
\begin{align*}
&a_{1j}(-1)^{1+j}\det{A_{1j}}=\\
=&a_{1j}(-1)^{1+j}\Big(a_{21}(-1)^{1+1}\det{(A_{1j})_{11}}+\ldots +a_{i1}(-1)^{(i-1)+1}\det{(A_{1j})_{(i-1)1}}+\ldots \Big)
\end{align*}
The entry $a_{i1}$ will only appear in the term $$a_{i1}(-1)^{(i-1)+1}\det{(A_{1j})_{(i-1)1}}$$
So, after we distribute $a_{1j}(-1)^{1+j}$, LHS will contain only one term of the form
$$a_{i1}a_{1j}(-1)^{p+q}\det{(A_{st})_{pq}}$$
But RHS also has only one term of this form.  We now need to show that these two terms are equal.  The two terms are
\begin{align*}a_{i1}(-1)^{i+1}a_{1j}(-1)^{1+(j-1)}\det{(A_{i1})_{1(j-1)}}=a_{i1}a_{1j}(-1)^{i+j+1}\det{(A_{i1})_{1(j-1)}}\end{align*}
and 
\begin{align*}a_{1j}(-1)^{1+j}a_{i1}(-1)^{(i-1)+1}\det{(A_{1j})_{(i-1)1}}=a_{i1}a_{1j}(-1)^{i+j+1}\det{(A_{1j})_{(i-1)1}}\end{align*}
Observe that $(A_{i1})_{1(j-1)}$ and $(A_{1j})_{(i-1)1}$ are the same matrix because both were obtained from matrix $A$ by deleting the first and the $i^{th}$ rows of $A$, and the first and the $j^{th}$ columns of $A$.  Therefore $\det{(A_{i1})_{1(j-1)}}=\det{(A_{1j})_{(i-1)1}}$.


We conclude that the terms of LHS and RHS match.  This establishes the desired equality.
\end{proof}

Now we know that cofactor expansion along the first row and cofactor expansion along the first column produce the same result, so either expansion can be used to find the determinant.  

\subsection*{Proof of Results Concerning Elementary Row Operations}
In \href{https://ximera.osu.edu/oerlinalg/LinearAlgebra/DET-0030/main}{Elementary Row Operations} we observed, without proof, the following properties of the determinant. (See Theorem \ref{th:elemrowopsanddet}.)
\begin{summary}
    Let $A=\begin{bmatrix}a_{ij}\end{bmatrix}$ be an $n\times n$ matrix.  
\begin{enumerate}
\item\label{item:rowswapanddetSUMM}
If $B$ is obtained from $A$ by interchanging two different rows, then $$\det{B}=-\det{A}$$
\item \label{item:rowconstantmultanddetSUMM}
If $B$ is obtained from $A$ by multiplying one of the rows of $A$ by a non-zero constant $k$.  Then $$\det{B}=k\det{A}$$
\item \label{item:addmultotherrowdetSUMM}
If $B$ is obtained from $A$ by adding a multiple of one row of $A$ to another row, then
$$\det{B}=\det{A}$$
\end{enumerate}
\end{summary}

We now prove these properties.
\begin{proof}[Proof of Theorem \ref{th:elemrowopsanddet}\ref{item:rowswapanddetSUMM}] We will start by showing that the result holds if two consecutive rows are interchanged.  Suppose $B$ is obtained from $A$ by swapping rows $p$ and $p+1$ of $A$. 

We proceed by induction on $n$.  The result is not applicable for $n=1$.  In Practice Problem \ref{prob:proofofrowswapanddet}, you will be asked to verify that the result holds for $2\times 2$ matrices.  Suppose that the result holds for $(n-1)\times (n-1)$ matrices.  We need to show that it holds for $n\times n$ matrices.
You may find the following diagram useful throughout the proof.
\begin{center}
\begin{tikzpicture}
  \matrix (mA)[
    matrix of math nodes,
    nodes in empty cells,
    left delimiter={[},right delimiter={]},minimum width=width("a22")] {
    a_{11} & a_{12} & \dots  & a_{1n}  \\
   \vdots & \vdots &  & \vdots \\
   a_{p1} & a_{p2} &\dots  & a_{pn}  \\
   a_{(p+1)1} & a_{(p+1)2} & \dots  & a_{(p+1)n}\\
   \vdots & \vdots &  & \vdots  \\
   a_{n1} & a_{n2} & \dots  & a_{nn}\\
  } ;
  
  \matrix (mB)[
    matrix of math nodes,
    nodes in empty cells,
    left delimiter={[},right delimiter={]},minimum width=width("a22")] at ($(mA.east)+(4,0)$)
    {
    a_{11} & a_{12} & \dots  & a_{1n}  \\
   \vdots & \vdots &  & \vdots \\
      a_{(p+1)1} & a_{(p+1)2} & \dots  & a_{(p+1)n}\\
      a_{p1} & a_{p2} &\dots  & a_{pn}  \\
   \vdots & \vdots &  & \vdots  \\
   a_{n1} & a_{n2} & \dots  & a_{nn}\\
  } ;
\draw [->](mA-3-4.east) -- (mB-4-1.west);
\draw [->](mA-4-4.east) -- (mB-3-1.west);
 \end{tikzpicture}
 \end{center} 
 Observe that for $i\neq p, p+1$ we have: $$b_{ij}=a_{ij}$$ Because $B_{ij}$ is obtained from $A_{ij}$ by switching two rows of $A_{ij}$, our induction hypothesis give us:
 $$\det{B_{ij}}=-\det{A_{ij}}$$
 
 For $i=p$ and $i=p+1$ we have:
 $$b_{p1}=a_{(p+1)1}\quad\text{and}\quad b_{(p+1)1}=a_{p1}$$
 $$B_{p1}=A_{(p+1)1}\quad\text{and}\quad B_{(p+1)1}=A_{p1}$$
 
 We compute the determinant of $B$ by cofactor expansion along the first column.
 \begin{align*}
 \det{B}&=b_{11}(-1)^{1+1}\det{B_{11}}+\ldots +b_{i1}(-1)^{i+1}\det{B_{i1}}+\ldots\\
 &+b_{p1}(-1)^{p+1}\det{B_{p1}}+b_{(p+1)1}(-1)^{(p+1)+1}\det{B_{(p+1)1}}+\ldots\\
 &+b_{n1}(-1)^{n+1}\det{B_{n1}}\\
 \\
 &=a_{11}(-1)^{1+1}(-1)\det{A_{11}}+\ldots +a_{i1}(-1)^{i+1}(-1)\det{A}_{i1}+\ldots\\
 &+a_{(p+1)1}(-1)^{p+1}\det{A_{(p+1)1}}+a_{p1}(-1)^{(p+1)+1}\det{A_{p1}}+\ldots\\
 &+a_{n1}(-1)^{n+1}(-1)\det{A_{n1}}\\
 \\
 &=a_{11}(-1)^{1+1}(-1)\det{A_{11}}+\ldots +a_{i1}(-1)^{i+1}(-1)\det{A_{i1}}+\ldots\\
 &+a_{(p+1)1}(-1)^{(p+1)+1}(-1)\det{A_{(p+1)1}}+a_{p1}(-1)^{p+1}(-1)\det{A_{p1}}+\ldots\\
 &+a_{n1}(-1)^{n+1}(-1)\det{A_{n1}}\\
 \\
 &=(-1)\Big(a_{11}(-1)^{1+1}\det{A_{11}}+\ldots +a_{i1}(-1)^{i+1}\det{A_{i1}}+\ldots\\
 &+a_{(p+1)1}(-1)^{(p+1)+1}\det{A_{(p+1)1}}+a_{p1}(-1)^{p+1}\det{A_{p1}}+\ldots\\
 &+a_{n1}(-1)^{n+1}\det{A_{n1}}\Big)\\
 \\
 &=-\det{A}
 \end{align*}
 
 If two non-adjacent rows are switched, then the switch can be carried out by performing an odd number of adjacent row interchanges (See Practice Problem \ref{prob:numberofrowswitches}), so the result still holds.
\end{proof}

\begin{proof}[Proof of Theorem \ref{th:elemrowopsanddet}\ref{item:rowconstantmultanddetSUMM}]
We proceed by induction on $n$.  Clearly the statement is true for $n=1$.  Just for fun, you might want to verify directly that it holds for $2\times 2$ matrices.  Now suppose the statement is true for all $(n-1)\times (n-1)$ matrices. We will show that it holds for $n\times n$ matrices.

Suppose $B$ is obtained from $A$ by multiplying the $p$'s row of $A$ by $k$.  

$$A=\begin{bmatrix} a_{11} & a_{12} & \dots  & a_{1n}  \\
   \vdots & \vdots &  & \vdots \\
   a_{p1} & a_{p2} &\dots  & a_{pn}  \\
   \vdots & \vdots &  & \vdots  \\
   a_{n1} & a_{n2} & \dots  & a_{nn}\end{bmatrix}\quad
   B=\begin{bmatrix} a_{11} & a_{12} & \dots  & a_{1n}  \\
   \vdots & \vdots &  & \vdots \\
   ka_{p1} & ka_{p2} &\dots  & ka_{pn}  \\
   \vdots & \vdots &  & \vdots  \\
   a_{n1} & a_{n2} & \dots  & a_{nn}\end{bmatrix}$$
   
   We compute the determinant of $B$ by cofactor expansion along the first column.
   \begin{align*}
   \det B &=a_{11}(-1)^{1+1}\det B_{11}+\ldots +ka_{p1}(-1)^{p+1}\det B_{p1}+\ldots \\
   &+ a_{n1}(-1)^{n+1}\det B_{n1}\\
   \\
   &=ka_{11}(-1)^{1+1}\det A_{11}+\ldots +ka_{p1}(-1)^{p+1}\det A_{p1}+\ldots \\
   &+ ka_{n1}(-1)^{n+1}\det A_{n1}\\
   \\
   &=k\Big(a_{11}(-1)^{1+1}\det A_{11}+\ldots +a_{p1}(-1)^{p+1}\det A_{p1}+\ldots \\
   &+ a_{n1}(-1)^{n+1}\det A_{n1}\Big)\\
   \\
   &=k\det A
   \end{align*}
\end{proof}

Before we tackle the proof of Part \ref{item:addmultotherrowdetSUMM} of Theorem \ref{th:elemrowopsanddet} we will need to prove the following lemma.




\begin{lemma}\label{lemma:arowsumofbc}
Let $A$, $B$ and $C$ be $n\times n$ matrices. Suppose $A$, $B$ and $C$ are identical, except for the $p^{th}$ row.  If the $p^{th}$ row of $C$ is the sum of the $p^{th}$ rows of $A$ and $B$, then
$$\det{C}=\det{A}+\det{B}$$
\end{lemma}
\begin{proof}
We will proceed by induction on $n$.  We leave it to the reader to verify cases $n=1, 2$.  We will assume that the statement holds for all $(n-1)\times (n-1)$ matrices and show that it holds for $n\times n$ matrices.

You may find the following representations of $A$, $B$ and $C$ helpful.  Identical entries in $A$, $B$ and $C$ are labeled $d_{ij}$.

$$A=\begin{bmatrix} d_{11} & d_{12} & \dots  & d_{1n}  \\
   \vdots & \vdots &  & \vdots \\
   a_{p1} & a_{p2} &\dots  & a_{pn}  \\
   \vdots & \vdots &  & \vdots  \\
   d_{n1} & d_{n2} & \dots  & d_{nn}\end{bmatrix}\quad
   B=\begin{bmatrix} d_{11} & d_{12} & \dots  & d_{1n}  \\
   \vdots & \vdots &  & \vdots \\
   b_{p1} & b_{p2} &\dots  & b_{pn}  \\
   \vdots & \vdots &  & \vdots  \\
   d_{n1} & d_{n2} & \dots  & d_{nn}\end{bmatrix}$$
   $$C=\begin{bmatrix} d_{11} & d_{12} & \dots  & d_{1n}  \\
   \vdots & \vdots &  & \vdots \\
   a_{p1}+b_{p1} & a_{p2}+b_{p2} &\dots  & a_{pn}+b_{pn}  \\
   \vdots & \vdots &  & \vdots  \\
   d_{n1} & d_{n2} & \dots  & d_{nn}\end{bmatrix}$$
Observe that $$A_{p1}=B_{p1}=C_{p1}$$  For $i\neq p$, the induction hypothesis gives us
$$\det{C_{i1}}=\det{A_{i1}}+\det{B_{i1}}$$
   
We now compute the determinant of $C$ by cofactor expansion along the first column.
\begin{align*}
\det{C}&=d_{11}(-1)^{1+1}\det{C_{11}}+\ldots +(a_{p1}+b_{p1})(-1)^{p+1}\det{C_{p1}}+\ldots\\
&+d_{n1}(-1)^{n+1}\det{C_{n1}}\\
\\
&=d_{11}(-1)^{1+1}\Big(\det{A_{11}}+\det{B_{11}}\Big)+\ldots\\
&+a_{p1}(-1)^{p+1}\det{C_{p1}}+b_{p1}(-1)^{p+1}\det{C_{p1}}+\ldots\\
&+d_{n1}(-1)^{n+1}\Big(\det{A_{n1}}+\det{B_{n1}}\Big)\\
\\
&=d_{11}(-1)^{1+1}\det{A_{11}}+d_{11}(-1)^{1+1}\det{B_{11}}+\ldots\\
&+a_{p1}(-1)^{p+1}\det{A_{p1}}+b_{p1}(-1)^{p+1}\det{B_{p1}}+\ldots\\
&+d_{n1}(-1)^{n+1}\det{A_{n1}}+d_{n1}(-1)^{n+1}\det{B_{n1}}\\
\\
&=\det{A}+\det{B}
\end{align*}
\end{proof}

We are now ready to finish the proof of Theorem \ref{th:elemrowopsanddet}
\begin{proof}[Proof of Theorem \ref{th:elemrowopsanddet}\ref{item:addmultotherrowdetSUMM}]
Suppose $B$ is obtained from $A$ by adding $k$ times row $p$ to row $q$.  ($p\neq q$ and $k\neq 0$)  You may find the following representations of $A$ and $B$ useful.
$$A=\begin{bmatrix} a_{11} & a_{12} & \dots  & a_{1n}  \\
   \vdots & \vdots &  & \vdots \\
   a_{p1} & a_{p2} &\dots  & a_{pn}  \\
   \vdots & \vdots &  & \vdots \\
   a_{q1} & a_{q2} &\dots  & a_{qn}  \\
   \vdots & \vdots &  & \vdots  \\
   a_{n1} & a_{n2} & \dots  & a_{nn}\end{bmatrix}\quad
   B=\begin{bmatrix} a_{11} & a_{12} & \dots  & a_{1n}  \\
   \vdots & \vdots &  & \vdots \\
   a_{p1} & a_{p2} & \dots  & a_{pn}  \\
   \vdots & \vdots &  & \vdots \\
   a_{q1}+ka_{p1} & a_{q2}+ka_{p2} &\dots  & a_{qn}+ka_{pn}  \\
   \vdots & \vdots &  & \vdots  \\
   a_{n1} & a_{n2} & \dots  & a_{nn}\end{bmatrix}$$
We will form another matrix $A'$ by replacing the $q^{th}$ row of $A$ with $k$ times the $p^{th}$ row.
$$A'=\begin{bmatrix} a_{11} & a_{12} & \dots  & a_{1n}  \\
   \vdots & \vdots &  & \vdots \\
   a_{p1} & a_{p2} &\dots  & a_{pn}  \\
   \vdots & \vdots &  & \vdots \\
   ka_{p1} & ka_{p2} &\dots  & ka_{pn}  \\
   \vdots & \vdots &  & \vdots  \\
   a_{n1} & a_{n2} & \dots  & a_{nn}\end{bmatrix}$$
Observe that matrices $A$, $A'$ and $B$ are identical except for the $q^{th}$ row, and the $q^{th}$ row of matrix $B$ is the sum of the $q^{th}$ rows of $A$ and $A'$.  Thus, by Lemma \ref{lemma:arowsumofbc}, we have:
$$\det{B}=\det{A}+\det{A'}$$
Since one row of $A'$ is a scalar multiple of another row, we know $\det{A'}=0$ (see Practice Problem \ref{prob:kAdet}). Therefore 
$\det{B}=\det{A}$.
   \end{proof}

\subsection*{The Laplace Expansion Theorem}
As we have seen in examples, the value of the determinant can be computed by expanding along any row or column.  This result is known as the Laplace Expansion Theorem.  We begin by generalizing some earlier definitions.

Given an $n\times n$ matrix 
$$A=\begin{bmatrix}a_{11} & a_{12} & \dots & a_{1(j-1)} & a_{1j} & a_{1(j+1)} & \dots & a_{1n}  \\
    a_{21} & a_{22} & \dots & a_{2(j-1)} & a_{2j} & a_{2(j+1)} & \dots & a_{2n}  \\
   \vdots & \vdots &  & \vdots & \vdots & \vdots &  & \vdots  \\
   a_{(i-1)1} & a_{(i-1)2} & \ldots & a_{(i-1)(j-1)} & a_{(i-1)j} & a_{(i-1)(j+1)} & \ldots & a_{(i-1)n}\\
  a_{i1} & a_{i2} & \ldots & a_{i(j-1)} & a_{ij} & a_{i(j+1)} & \ldots & a_{in}\\
  a_{(i+1)1} & a_{(i+1)2} & \ldots & a_{(i+1)(j-1)} & a_{(i+1)j} & a_{(i+1)(j+1)} & \ldots & a_{(i+1)n}\\
  \vdots & \vdots &  & \vdots & \vdots & \vdots &  & \vdots  \\
   a_{n1} & a_{n2} & \dots & a_{n(j-1)} & a_{nj} & a_{n(j+1)} & \dots & a_{nn}\end{bmatrix}$$
   define the \dfn{minor} $A_{ij}$ to be an $(n-1)\times (n-1)$ matrix obtained from $A$ by deleting the $i^{th}$ row and the $j^{th}$ column of $A$.
\begin{center}
\begin{tikzpicture}
  \matrix (m)[
    matrix of math nodes,
    nodes in empty cells,
    left delimiter={[},right delimiter={]},minimum width=width("a(i-1)(j-1)")] {
    a_{11} & a_{12} & \dots & a_{1(j-1)} & a_{1j} & a_{1(j+1)} & \dots & a_{1n}  \\
    a_{21} & a_{22} & \dots & a_{2(j-1)} & a_{2j} & a_{2(j+1)} & \dots & a_{2n}  \\
   \vdots & \vdots &  & \vdots & \vdots & \vdots &  & \vdots  \\
   a_{(i-1)1} & a_{(i-1)2} & \ldots & a_{(i-1)(j-1)} & a_{(i-1)j} & a_{(i-1)(j+1)} & \ldots & a_{(i-1)n}\\
  a_{i1} & a_{i2} & \ldots & a_{i(j-1)} & a_{ij} & a_{i(j+1)} & \ldots & a_{in}\\
  a_{(i+1)1} & a_{(i+1)2} & \ldots & a_{(i+1)(j-1)} & a_{(i+1)j} & a_{(i+1)(j+1)} & \ldots & a_{(i+1)n}\\
  \vdots & \vdots &  & \vdots & \vdots & \vdots &  & \vdots  \\
   a_{n1} & a_{n2} & \dots & a_{n(j-1)} & a_{nj} & a_{n(j+1)} & \dots & a_{nn}  \\
  } ;
\draw (m-1-1.north west) rectangle (m-4-4.south east);
\draw (m-1-6.north west) rectangle (m-4-8.south east);
\draw (m-6-1.north west) rectangle (m-8-4.south east);
\draw (m-6-6.north west) rectangle (m-8-8.south east);
 
  \end{tikzpicture}
 \end{center} 
 
 Define the \dfn{$(i,j)$-cofactor} of $A$ by
 $$C_{ij}=(-1)^{i+j}\det(A_{ij})$$
 Note that the sign of $(-1)^{i+j}$ follows a checkerboard pattern.
 $$\begin{bmatrix}+&-&+&-&+&\ldots\\-&+&-&+&-&\ldots\\
 +&-&+&-&+&\ldots\\-&+&-&+&-&\ldots\\\vdots &\vdots  & \vdots & \vdots &\vdots &\ddots \end{bmatrix}$$

\begin{theorem}[Laplace Expansion Theorem]\label{th:laplace1}
Let $A=\begin{bmatrix}a_{ij}\end{bmatrix}$ be an $n\times n$ matrix.  Then each of the following computations produces $\det{A}$.
\begin{enumerate}
    \item \label{eq:laplace1a} \dfn{Cofactor Expansion along the $i^{th}$ row}
\begin{align*}
\det{A}&=a_{i1}C_{i1}+a_{i2}C_{i2}+\ldots +a_{in}C_{in}\\
&=a_{i1}(-1)^{i+1}\det{A_{i1}}+a_{i2}(-1)^{i+2}\det{A_{i2}}+\ldots +a_{in}(-1)^{i+n}\det{A_{in}}\\
&=\sum_{j=1}^na_{ij}(-1)^{i+j}\det{A_{ij}}
\end{align*}
\item \label{eq:laplace1b} \dfn{Cofactor Expansion along the $j^{th}$ column}
\begin{align*}
\det{A}&=a_{1j}C_{1j}+a_{2j}C_{2j}+\ldots +a_{nj}C_{nj}\\
&=a_{1j}(-1)^{1+j}\det{A_{1j}}+a_{2j}(-1)^{2+j}\det{A_{2j}}+\ldots +a_{nj}(-1)^{n+j}\det{A_{nj}}\\
&=\sum_{i=1}^na_{ij}(-1)^{i+j}\det{A_{ij}}
\end{align*}
\end{enumerate}
\end{theorem}
 
 %Computation (\ref{eq:laplace1a}) is called the \dfn{cofactor expansion along the $i^{th}$ row}.  Computation (\ref{eq:laplace1b}) is called \dfn{cofactor expansion along the $j^{th}$ column}.  
 
%  \begin{example}\label{ex:laplace1}
% Let  
% $$A=\begin{bmatrix}4&-1&2&1\\3&0&1&-2\\
% 2&1&5&1\\-2&1&3&-1\end{bmatrix}$$
% Find $\det{A}$ by cofactor expansion along the second row.
% \begin{explanation}
% Matrix $A$ is the same as the matrix in Example \ref{ex:expansiontoprow} of DET-0010.  According to the Laplace Expansion Theorem we should get the same value for the determinant as we did in Example \ref{ex:expansiontoprow} regardless of which row or column we expand along.  The second row has the advantage over other rows in that it contains a zero.  This makes computing one of the cofactors unnecessary.  Following the checker board sign pattern along the second row we get

% \begin{align*}
% \det{A}&=-(3)\det{A_{21}}+(0)\det{A_{22}}-(1)\det{A_{23}}+(-2)\det{A_{24}}\\
% &=-3\begin{vmatrix}-1&2&1\\1&5&1\\1&3&-1\end{vmatrix}-\begin{vmatrix}4&-1&1\\2&1&1\\-2&1&-1\end{vmatrix}+(-2)\begin{vmatrix}4&-1&2\\2&1&5\\-2&1&3\end{vmatrix}\\&=-3(\answer{10})-(\answer{-4})-2(\answer{16})\\
% &=\answer{-58}
% \end{align*}
% This answer is the same as the answer we got using cofactor expansion along the first row in Example \ref{ex:expansiontoprow}.
% \end{explanation}
%  \end{example}
 
%It is clear that having zeros as entries in the matrix significantly reduces the number of computations necessary to find the determinant.  The following example demonstrates how Laplace Expansion Theorem allows us to use zeros to our advantage.

% \begin{example}\label{ex:laplace2}
% Find $\det{A}$ if
% $$A=\begin{bmatrix}4&0&0&0&2\\0&-1&1&0&0\\2&0&0&-5&3\\0&1&4&0&-1\\1&1&5&0&0\end{bmatrix}$$

% \begin{explanation}
% The fourth column contains the most zeros, so we will expand along that column.  The  $(3, 4)$-entry is the only non-zero entry in the fourth column.  So the sign is given by $(-1)^{3+4}=-1$.  You can also consult the checker board pattern to confirm this.  
% $$\det{A}=-(-5)\begin{vmatrix}4&0&0&2\\0&-1&1&0\\0&1&4&-1\\1&1&5&0\end{vmatrix}
% $$
% Next we will expand along the top row.
% $$\det{A}=5\left(4\begin{vmatrix}-1&1&0\\1&4&-1\\1&5&0\end{vmatrix}-2\begin{vmatrix}0&-1&1\\0&1&4&\\1&1&5\end{vmatrix}\right)$$
% Try the next step on your own.  We suggest that you expand the first matrix along the last column and expand the second matrix along the first column.
% $$\det(A)=5\big(4(\answer{-6})-2(\answer{-5})\big)=\answer{-70}$$
% \end{explanation}
% \end{example}
\begin{proof}
We will start by showing that cofactor expansion along column $j$ produces the same result as cofactor expansion along the first column.  Observe that column $j$ can be shifted into the first column position by $j-1$ consecutive row switches.  Let $A'=\begin{bmatrix}a'_{ij}\end{bmatrix}$ be the matrix obtained from $A$ by performing the necessary column switches.  Then 
\begin{align*}
\det{A}&=(-1)^{j-1}\det{A'}\\
&=(-1)^{j-1}\sum_{i=1}^na'_{i1}(-1)^{i+1}\det{A'_{i1}}\\
&=(-1)^{j-1}\sum_{i=1}^na_{ij}(-1)^{i+1}\det{A_{ij}}\\
&=\sum_{i=1}^na_{ij}(-1)^{j-1}(-1)^{i+1}\det{A_{ij}}\\
&=\sum_{i=1}^na_{ij}(-1)^{i+j}\det{A_{ij}}
\end{align*}

To show that the determinant of $A$ can also be computed by cofactor expansion along any row follows from the fact that $\det{A}=\det{A^T}$. (Theorem \ref{th:detoftrans})
\end{proof}
\section*{Practice Problems}

\begin{problem}\label{prob:proofofrowswapanddet}
Complete the proof of Theorem \ref{th:elemrowopsanddet}\ref{item:rowswapanddet} by showing that the result holds for a $2\times 2$ matrix.
\end{problem}

\begin{problem}\label{prob:numberofrowswitches}
Let $p$ and $q$ be two rows of a matrix, with $p<q$.  Show that the switch of $p$ and $q$ requires $2(q-p)-1$ adjacent row interchanges.
\end{problem}



\end{document} 